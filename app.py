"""
TMIV - The Most Important Variables
Kompletna aplikacja AutoML z czystÄ… architekturÄ…
"""
from __future__ import annotations

import streamlit as st
from pathlib import Path
from typing import Dict, Any, Optional, Tuple
import pandas as pd
import numpy as np
from dataclasses import dataclass, field
import json
import logging
import io

# Konfiguracja strony - musi byÄ‡ pierwsza
st.set_page_config(
    page_title="TMIV - The Most Important Variables",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Importy moduÅ‚Ã³w aplikacji - z obsÅ‚ugÄ… bÅ‚Ä™dÃ³w
missing_modules = []

try:
    import plotly.express as px
except ImportError:
    missing_modules.append("plotly")
    px = None

try:
    from settings import get_settings  # Bez "config."
    # Test czy dziaÅ‚a
    test_settings = get_settings()
    if not hasattr(test_settings, 'data_max_file_size_mb'):
        raise ImportError("Settings object missing data configuration")
except ImportError:
    missing_modules.append("settings")
    def get_settings():
        class MockData:
            max_file_size_mb = 200
            supported_formats = [".csv", ".xlsx", ".json"]
        
        class MockSettings:
            app_name = "TMIV - The Most Important Variables"
            data = MockData()
            def get_feature_flag(self, flag): 
                return True
        
        return MockSettings()

try:
    from frontend.ui_components import TMIVApp, DataConfig, UIConfig
except ImportError:
    missing_modules.append("frontend.ui_components")
    class DataConfig:
        def __init__(self, **kwargs): pass
    class UIConfig:
        def __init__(self, **kwargs):
            self.app_title = kwargs.get("app_title", "TMIV")
            self.app_subtitle = kwargs.get("app_subtitle", "AutoML Tool")
    class TMIVApp:
        def __init__(self, data_config, ui_config): pass
        def render_data_selection(self):
            st.info("Upload CSV file to continue")
            uploaded_file = st.file_uploader("Choose CSV file", type=['csv'])
            if uploaded_file:
                df = pd.read_csv(uploaded_file)
                # Auto detect target
                target = None
                for col in df.columns:
                    if any(word in col.lower() for word in ['target', 'y', 'price', 'label']):
                        target = col
                        break
                if not target and len(df.columns) > 1:
                    target = df.columns[-1]
                return df, uploaded_file.name, target
            return None, None, None

try:
    from backend.ml_integration import train_sklearn_enhanced, ModelConfig
except ImportError:
    missing_modules.append("backend.ml_integration")
    class ModelConfig:
        def __init__(self, **kwargs): pass
    def train_sklearn_enhanced(df, config):
        # Mock training
        from sklearn.ensemble import RandomForestRegressor
        from sklearn.model_selection import train_test_split
        from sklearn.metrics import mean_squared_error, r2_score
        
        target = config.target
        X = df.drop(columns=[target])
        y = df[target]
        
        # Simple preprocessing
        X = X.select_dtypes(include=[np.number]).fillna(0)
        
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = RandomForestRegressor(random_state=42)
        model.fit(X_train, y_train)
        
        y_pred = model.predict(X_test)
        
        metrics = {
            "r2": r2_score(y_test, y_pred),
            "rmse": mean_squared_error(y_test, y_pred, squared=False)
        }
        
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        metadata = {"engine": "mock", "run_time": 1.0}
        
        return model, metrics, feature_importance, metadata

try:
    from backend.eda_integration import SmartDataPreprocessor
except ImportError:
    missing_modules.append("backend.eda_integration") 
    class SmartDataPreprocessor:
        def preprocess(self, df, target=None):
            # Simple preprocessing
            df_clean = df.copy()
            # Drop columns with >90% missing
            for col in df_clean.columns:
                if df_clean[col].isna().sum() / len(df_clean) > 0.9:
                    df_clean = df_clean.drop(columns=[col])
            
            # Fill numeric missing with median
            numeric_cols = df_clean.select_dtypes(include=[np.number]).columns
            for col in numeric_cols:
                if col != target:
                    df_clean[col] = df_clean[col].fillna(df_clean[col].median())
            
            class Report:
                def __init__(self):
                    self.original_shape = df.shape
                    self.final_shape = df_clean.shape
                    self.processing_time = 1.0
                def to_dict(self):
                    return {"preprocessing": "completed"}
            
            return df_clean, Report()

try:
    from backend.utils import SmartTargetDetector, MLRecommendationEngine
except ImportError:
    missing_modules.append("backend.utils")
    class SmartTargetDetector:
        def detect_target(self, df, preferred=None):
            if preferred and preferred in df.columns:
                return preferred
            for col in df.columns:
                if any(word in col.lower() for word in ['target', 'y', 'price', 'label']):
                    return col
            return df.columns[-1] if len(df.columns) > 0 else None
        
        def analyze_target(self, df, target_col):
            class Analysis:
                def __init__(self):
                    self.problem_type = type('obj', (object,), {'value': 'regression'})()
                    self.unique_values = df[target_col].nunique()
                    self.missing_ratio = df[target_col].isna().sum() / len(df)
            return Analysis()
    
    class MLRecommendationEngine:
        def generate_recommendations(self, analysis=None, **kwargs):
            return """
# Podstawowe rekomendacje ML

- SprawdÅº jakoÅ›Ä‡ danych i usuÅ„ outliery
- Przetestuj rÃ³Å¼ne algorytmy ML
- UÅ¼yj cross-validation do oceny modelu
- Monitoruj performance w czasie
            """

try:
    from db.db_utils import MLExperimentTracker, RunRecord, ProblemType, RunStatus
except ImportError:
    missing_modules.append("db.db_utils")
    class ProblemType:
        REGRESSION = "regression"
        BINARY_CLASSIFICATION = "classification"
    class RunStatus:
        COMPLETED = "completed"
    class RunRecord:
        def __init__(self, **kwargs): pass
    class MLExperimentTracker:
        def __init__(self): 
            self.history = []
        
        def get_history(self): 
            return pd.DataFrame(self.history) if self.history else pd.DataFrame()
        
        def log_run(self, record): 
            self.history.append({
                "run_id": getattr(record, 'run_id', 'test'),
                "dataset": getattr(record, 'dataset', 'unknown'),
                "target": getattr(record, 'target', 'unknown')
            })
            return True
        
        def get_statistics(self): 
            return {"total_runs": len(self.history)}
        
        def export_to_csv(self): 
            return "run_id,dataset,target\n"
        
        def clear_history(self, confirm=False): 
            self.history = []
        
        def backup_database(self): 
            return Path("backup.db")

# Logger
logger = logging.getLogger(__name__)

# CSS dla lepszego wyglÄ…du
st.markdown("""
<style>
[data-testid="stMetricLabel"] > div {
    white-space: normal;
    word-wrap: break-word;
    text-align: center;
}
.stSuccess > div { border-left: 4px solid #28a745; }
.stError > div { border-left: 4px solid #dc3545; }
.stWarning > div { border-left: 4px solid #ffc107; }
</style>
""", unsafe_allow_html=True)

@dataclass
class AppState:
    """Stan aplikacji - centralne zarzÄ…dzanie"""
    model: Optional[Any] = None
    metrics: Dict[str, float] = field(default_factory=dict)
    feature_importance: pd.DataFrame = field(default_factory=pd.DataFrame)
    metadata: Dict[str, Any] = field(default_factory=dict)
    dataset: Optional[pd.DataFrame] = None
    dataset_name: str = ""
    target_column: str = ""
    preprocessing_info: Dict[str, Any] = field(default_factory=dict)
    training_completed: bool = False

def init_app_state() -> AppState:
    """Inicjalizuje stan aplikacji"""
    if "app_state" not in st.session_state:
        st.session_state.app_state = AppState()
    return st.session_state.app_state

def get_openai_key() -> str:
    """Pobiera klucz OpenAI z rÃ³Å¼nych ÅºrÃ³deÅ‚"""
    import os
    import re
    
    # SprawdÅº session_state, secrets, env
    sources = [
        st.session_state.get("openai_key", ""),
        getattr(st.secrets, "OPENAI_API_KEY", "") if hasattr(st, 'secrets') else "",
        os.getenv("OPENAI_API_KEY", "")
    ]
    
    for key in sources:
        if key and re.match(r"^sk-[a-zA-Z0-9]{20,}$", key):
            return key
    return ""

class TMIVApplication:
    """GÅ‚Ã³wna klasa aplikacji TMIV"""
    
    # Dodaj te metody do klasy TMIVApplication w app.py:

def _render_predictions(self):
    """Renderuje sekcjÄ™ predykcji."""
    if not self.state.model:
        return
    
    st.subheader("ğŸ”® Predykcje")
    
    with st.expander("ğŸ“Š Testowe predykcje", expanded=False):
        if self.state.dataset is not None:
            # WeÅº prÃ³bkÄ™ danych
            sample_data = self.state.dataset.head(10).drop(columns=[self.state.target_column], errors='ignore')
            
            try:
                predictions = self.state.model.predict(sample_data)
                
                # WyÅ›wietl wyniki
                results_df = sample_data.copy()
                results_df['Predykcja'] = predictions
                st.dataframe(results_df, use_container_width=True)
                
            except Exception as e:
                st.error(f"BÅ‚Ä…d predykcji: {e}")

def _render_history_section(self):
    """Renderuje sekcjÄ™ historii eksperymentÃ³w."""
    st.markdown("## ğŸ“š Historia eksperymentÃ³w")
    
    try:
        history = self.experiment_tracker.get_history()
        
        if history.empty:
            st.info("ğŸ†• Brak historii eksperymentÃ³w. PrzeprowadÅº pierwszy eksperyment!")
            return
        
        # Podstawowe statystyki
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            total_runs = len(history)
            st.metric("ÅÄ…czne eksperymenty", total_runs)
        
        with col2:
            completed = len(history[history['status'] == 'completed']) if 'status' in history.columns else 0
            st.metric("UkoÅ„czone", completed)
        
        with col3:
            unique_datasets = history['dataset'].nunique() if 'dataset' in history.columns else 0
            st.metric("Unikalne datasety", unique_datasets)
        
        with col4:
            unique_targets = history['target'].nunique() if 'target' in history.columns else 0
            st.metric("Unikalne targety", unique_targets)
        
        # Tabela historii
        with st.expander("ğŸ“‹ SzczegÃ³Å‚y eksperymentÃ³w", expanded=True):
            # Wybierz kolumny do wyÅ›wietlenia
            display_columns = ['run_id', 'dataset', 'target', 'created_at']
            available_columns = [col for col in display_columns if col in history.columns]
            
            if available_columns:
                st.dataframe(
                    history[available_columns].head(20), 
                    use_container_width=True
                )
            else:
                st.dataframe(history.head(20), use_container_width=True)
        
    except Exception as e:
        st.error(f"BÅ‚Ä…d podczas Å‚adowania historii: {e}")
        logger.exception("Failed to render history section")

def _render_sidebar_tools(self):
    """Renderuje narzÄ™dzia w sidebarze."""
    with st.sidebar:
        st.header("ğŸ›  NarzÄ™dzia")
        
        # Eksport wynikÃ³w
        if self.state.training_completed:
            if st.button("ğŸ“¥ Eksportuj wyniki", use_container_width=True):
                self._export_results()
        
        # Historia eksperymentÃ³w
        st.subheader("ğŸ“š Historia")
        
        # Statystyki
        try:
            stats = self.experiment_tracker.get_statistics()
            total_runs = stats.get('total_runs', 0)
            st.metric("Eksperymenty", total_runs)
        except Exception:
            st.metric("Eksperymenty", "âŒ")
        
        # ZarzÄ…dzanie historiÄ…
        with st.expander("âš™ï¸ ZarzÄ…dzanie"):
            if st.button("ğŸ—‘ WyczyÅ›Ä‡ historiÄ™", type="secondary"):
                if st.checkbox("PotwierdÅº usuniÄ™cie"):
                    self.experiment_tracker.clear_history(confirm=True)
                    st.success("Historia wyczyszczona!")
                    st.rerun()
            
            if st.button("ğŸ’¾ Backup bazy", type="secondary"):
                backup_path = self.experiment_tracker.backup_database()
                if backup_path:
                    st.success(f"Backup: {backup_path}")

def _reset_state(self):
    """Resetuje stan aplikacji."""
    # WyczyÅ›Ä‡ stan treningu
    self.state.model = None
    self.state.metrics = {}
    self.state.feature_importance = pd.DataFrame()
    self.state.metadata = {}
    self.state.training_completed = False
    
    st.success("ğŸ”„ Stan aplikacji zostaÅ‚ zresetowany")
    st.rerun()

def _export_results(self):
    """Eksportuje wyniki eksperymentu."""
    if not self.state.training_completed:
        st.warning("Brak wynikÃ³w do eksportu")
        return
    
    try:
        # Przygotuj dane do eksportu
        export_data = {
            "dataset_name": self.state.dataset_name,
            "target_column": self.state.target_column,
            "metrics": self.state.metrics,
            "feature_importance": self.state.feature_importance.to_dict('records') if not self.state.feature_importance.empty else [],
            "metadata": self.state.metadata,
            "timestamp": pd.Timestamp.now().isoformat()
        }
        
        # Konwertuj do JSON
        import json
        json_data = json.dumps(export_data, indent=2, ensure_ascii=False, default=str)
        
        # UtwÃ³rz przycisk download
        st.download_button(
            label="ğŸ“ Pobierz wyniki (JSON)",
            data=json_data,
            file_name=f"tmiv_results_{self.state.dataset_name}_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json",
            mime="application/json"
        )
        
        st.success("âœ… Wyniki gotowe do pobrania!")
        
    except Exception as e:
        st.error(f"BÅ‚Ä…d eksportu: {e}")
        logger.exception("Failed to export results")

    def __init__(self):
        self.settings = get_settings()
        self.state = init_app_state()
        self.experiment_tracker = MLExperimentTracker()
        self._setup_configs()
        
    def _setup_configs(self):
        """Konfiguruje komponenty aplikacji"""
        # Bezpieczne pobieranie atrybutÃ³w
        max_size = getattr(getattr(self.settings, 'data', None), 'max_file_size_mb', 200)
        formats = getattr(getattr(self.settings, 'data', None), 'supported_formats', ['.csv', '.xlsx'])
        app_title = getattr(self.settings, 'app_name', 'TMIV')
        
        self.data_config = DataConfig(
            max_file_size_mb=max_size,
            supported_formats=formats,
            auto_detect_encoding=True,
            max_preview_rows=50
        )
        
        self.ui_config = UIConfig(
            app_title=app_title,
            app_subtitle="AutoML â€¢ EDA â€¢ Historia eksperymentÃ³w",
            enable_llm=bool(get_openai_key()),
            show_advanced_options=True
        )
        
        self.tmiv_app = TMIVApp(self.data_config, self.ui_config)
        
    def run(self):
        """GÅ‚Ã³wny punkt wejÅ›cia aplikacji"""
        # PokaÅ¼ ostrzeÅ¼enia o brakujÄ…cych moduÅ‚ach
        if missing_modules:
            st.warning(f"BrakujÄ…ce moduÅ‚y (uÅ¼ywam mock): {', '.join(missing_modules)}")
        
        self._render_header()
        self._render_openai_status()
        
        # GÅ‚Ã³wny przepÅ‚yw
        if not self.state.training_completed:
            self._data_loading_phase()
        else:
            self._results_phase()
        
        # Sekcje dostÄ™pne zawsze
        self._render_history_section()
        self._render_sidebar_tools()
        
    def _render_header(self):
        """Renderuje nagÅ‚Ã³wek aplikacji"""
        st.title(self.ui_config.app_title)
        st.caption(self.ui_config.app_subtitle)
        
        # Status aplikacji
        col1, col2, col3 = st.columns([2, 1, 1])
        with col1:
            if self.state.dataset is not None:
                st.success(f"ğŸ“Š Dane: {self.state.dataset_name} ({len(self.state.dataset)} wierszy)")
            else:
                st.info("ğŸ“ Wczytaj dane aby rozpoczÄ…Ä‡")
                
        with col2:
            if self.state.training_completed:
                st.success("ğŸ¯ Model gotowy")
            else:
                st.info("â³ Oczekuje na trening")
                
        with col3:
            history = self.experiment_tracker.get_history()
            experiments_count = len(history) if history is not None else 0
            st.metric("Eksperymenty", experiments_count)
    
    def _render_openai_status(self):
        """Status klucza OpenAI"""
        openai_key = get_openai_key()
        
        if openai_key:
            st.success("ğŸ¤– OpenAI aktywny - opisy kolumn i rekomendacje dostÄ™pne")
        else:
            with st.expander("ğŸ”‘ Konfiguracja OpenAI (opcjonalne)"):
                key_input = st.text_input(
                    "Klucz OpenAI API",
                    type="password",
                    placeholder="sk-...",
                    help="Dla opisÃ³w kolumn i rekomendacji AI"
                )
                if key_input:
                    st.session_state["openai_key"] = key_input
                    st.rerun()
    
    def _data_loading_phase(self):
        """Faza wczytywania i konfiguracji danych"""
        st.markdown("## ğŸ“Š Przygotowanie danych")
        
        # Wczytywanie danych
        df, dataset_name, target = self.tmiv_app.render_data_selection()
        
        if df is None or df.empty:
            st.info("ğŸ‘† Wczytaj dane aby kontynuowaÄ‡")
            return
            
        # Aktualizuj stan
        self.state.dataset = df
        self.state.dataset_name = dataset_name
        self.state.target_column = target or ""
        
        # EDA sekcja
        self._render_eda_section(df)
        
        # Trening
        if target:
            self._render_training_section(df, target)
    
    def _render_eda_section(self, df: pd.DataFrame):
        """Sekcja analizy eksploracyjnej"""
        st.markdown("## ğŸ”¬ Analiza eksploracyjna")
        
        # Szybkie podsumowanie
        with st.expander("ğŸ“‹ Podsumowanie danych", expanded=True):
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("Wiersze", f"{len(df):,}")
            with col2:
                st.metric("Kolumny", len(df.columns))
            with col3:
                missing_pct = (df.isna().sum().sum() / df.size) * 100
                st.metric("Braki danych", f"{missing_pct:.1f}%")
            with col4:
                duplicates = df.duplicated().sum()
                st.metric("Duplikaty", duplicates)
        
        # WybÃ³r typu analizy
        analysis_type = st.selectbox(
            "Rodzaj analizy",
            [
                "Podsumowanie statystyczne",
                "RozkÅ‚ady zmiennych", 
                "Korelacje",
                "Analiza targetu",
                "JakoÅ›Ä‡ danych"
            ]
        )
        
        if analysis_type == "Podsumowanie statystyczne":
            st.dataframe(df.describe(include='all'), use_container_width=True)
            
        elif analysis_type == "RozkÅ‚ady zmiennych":
            self._render_distributions(df)
            
        elif analysis_type == "Korelacje":
            self._render_correlations(df)
            
        elif analysis_type == "Analiza targetu":
            self._render_target_analysis(df)
            
        elif analysis_type == "JakoÅ›Ä‡ danych":
            self._render_data_quality(df)
    
    def _render_distributions(self, df: pd.DataFrame):
        """Renderuje rozkÅ‚ady zmiennych"""
        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
        
        if not numeric_cols:
            st.info("Brak zmiennych numerycznych")
            return
            
        selected_cols = st.multiselect(
            "Wybierz kolumny", 
            numeric_cols, 
            default=numeric_cols[:3]
        )
        
        if selected_cols and px:
            for col in selected_cols:
                st.subheader(f"RozkÅ‚ad: {col}")
                fig = px.histogram(df, x=col, marginal="box")
                st.plotly_chart(fig, use_container_width=True)
        elif selected_cols:
            # Fallback bez plotly
            for col in selected_cols:
                st.subheader(f"Statystyki: {col}")
                st.write(df[col].describe())
    
    def _render_correlations(self, df: pd.DataFrame):
        """Renderuje analizÄ™ korelacji"""
        numeric_df = df.select_dtypes(include=[np.number])
        
        if len(numeric_df.columns) < 2:
            st.info("Potrzeba co najmniej 2 zmiennych numerycznych")
            return
            
        corr_matrix = numeric_df.corr()
        
        if px:
            # Heatmapa
            fig = px.imshow(
                corr_matrix,
                text_auto=True,
                aspect="auto",
                color_continuous_scale="RdBu_r",
                title="Macierz korelacji"
            )
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.dataframe(corr_matrix)
        
        # Silne korelacje
        strong_corr = []
        for i in range(len(corr_matrix.columns)):
            for j in range(i+1, len(corr_matrix.columns)):
                corr_val = corr_matrix.iloc[i, j]
                if abs(corr_val) > 0.7:
                    strong_corr.append({
                        'Zmienna 1': corr_matrix.columns[i],
                        'Zmienna 2': corr_matrix.columns[j],
                        'Korelacja': round(corr_val, 3)
                    })
        
        if strong_corr:
            st.subheader("Silne korelacje (|r| > 0.7)")
            st.dataframe(pd.DataFrame(strong_corr), use_container_width=True)
    
    def _render_target_analysis(self, df: pd.DataFrame):
        """Analiza zmiennej docelowej"""
        if not self.state.target_column:
            st.info("Wybierz zmiennÄ… docelowÄ…")
            return
            
        target_col = self.state.target_column
        detector = SmartTargetDetector()
        
        try:
            analysis = detector.analyze_target(df, target_col)
            
            # Podstawowe informacje
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Typ problemu", getattr(analysis.problem_type, 'value', 'unknown'))
            with col2:
                st.metric("Unikalne wartoÅ›ci", analysis.unique_values)
            with col3:
                st.metric("Braki danych", f"{analysis.missing_ratio:.1%}")
            
            # Wizualizacja rozkÅ‚adu
            if px and getattr(analysis.problem_type, 'value', '') == "regression":
                fig = px.histogram(df, x=target_col, marginal="box")
                st.plotly_chart(fig, use_container_width=True)
            elif px:
                value_counts = df[target_col].value_counts()
                fig = px.bar(x=value_counts.index, y=value_counts.values)
                st.plotly_chart(fig, use_container_width=True)
            else:
                st.write("Statystyki podstawowe:")
                st.write(df[target_col].describe())
                
        except Exception as e:
            st.error(f"BÅ‚Ä…d analizy targetu: {e}")
    
    def _render_data_quality(self, df: pd.DataFrame):
        """Analiza jakoÅ›ci danych"""
        quality_issues = []
        
        # Sprawdzenie brakÃ³w danych
        missing = df.isnull().sum()
        for col, miss_count in missing.items():
            if miss_count > 0:
                miss_pct = (miss_count / len(df)) * 100
                quality_issues.append({
                    'Kolumna': col,
                    'Problem': 'Braki danych',
                    'WartoÅ›Ä‡': f"{miss_pct:.1f}% ({miss_count} wierszy)"
                })
        
        # Sprawdzenie kolumn staÅ‚ych
        for col in df.columns:
            if df[col].nunique() <= 1:
                quality_issues.append({
                    'Kolumna': col,
                    'Problem': 'Kolumna staÅ‚a',
                    'WartoÅ›Ä‡': f"{df[col].nunique()} unikatowych wartoÅ›ci"
                })
        
        # Sprawdzenie wysokiej kardynalnoÅ›ci
        for col in df.select_dtypes(include=['object']).columns:
            unique_ratio = df[col].nunique() / len(df)
            if unique_ratio > 0.8:
                quality_issues.append({
                    'Kolumna': col,
                    'Problem': 'Wysoka kardynalnoÅ›Ä‡',
                    'WartoÅ›Ä‡': f"{df[col].nunique()} unikalnych z {len(df)}"
                })
        
        if quality_issues:
            st.dataframe(pd.DataFrame(quality_issues), use_container_width=True)
        else:
            st.success("Nie wykryto problemÃ³w z jakoÅ›ciÄ… danych")
    
    def _render_training_section(self, df: pd.DataFrame, target: str):
        """Sekcja treningu modelu"""
        st.markdown("## ğŸš€ Trening modelu")
        
        # Konfiguracja treningu
        with st.expander("âš™ï¸ Konfiguracja treningu", expanded=False):
            col1, col2 = st.columns(2)
            
            with col1:
                cv_folds = st.slider("Cross-validation (folds)", 0, 10, 5)
                remove_outliers = st.checkbox("UsuÅ„ outliery", value=True)
                
            with col2:
                hyperopt_trials = st.slider("Optymalizacja hiperparametrÃ³w", 10, 200, 50)
                compute_shap = st.checkbox("Oblicz SHAP values", value=len(df) < 1000)
        
        # Przycisk treningu
        if st.button("ğŸ¯ Rozpocznij trening", type="primary", use_container_width=True):
            self._train_model(df, target, cv_folds, remove_outliers, hyperopt_trials, compute_shap)
    
    def _train_model(self, df: pd.DataFrame, target: str, cv_folds: int, 
                    remove_outliers: bool, hyperopt_trials: int, compute_shap: bool):
        """Wykonuje trening modelu"""
        
        with st.status("ğŸ”„ Trening w toku...", expanded=True) as status:
            try:
                # Preprocessing
                st.write("ğŸ“‹ Przygotowanie danych...")
                preprocessor = SmartDataPreprocessor()
                df_processed, prep_report = preprocessor.preprocess(df, target)
                
                # Konfiguracja modelu
                st.write("âš™ï¸ Konfiguracja modelu...")
                model_config = ModelConfig(
                    target=target,
                    cv_folds=cv_folds,
                    hyperopt_trials=hyperopt_trials,
                    outlier_detection=remove_outliers
                )
                
                # Trening
                st.write("ğŸ¯ Trening modelu...")
                model, metrics, fi_df, metadata = train_sklearn_enhanced(df_processed, model_config)
                
                # Aktualizacja stanu
                self.state.model = model
                self.state.metrics = metrics
                self.state.feature_importance = fi_df
                self.state.metadata = metadata
                self.state.preprocessing_info = prep_report.to_dict()
                self.state.training_completed = True
                
                # Zapis do historii
                st.write("ğŸ’¾ Zapisywanie eksperymentu...")
                self._save_experiment(metrics, metadata)
                
                status.update(label="âœ… Trening zakoÅ„czony pomyÅ›lnie", state="complete")
                st.balloons()
                
            except Exception as e:
                status.update(label="âŒ BÅ‚Ä…d treningu", state="error")
                st.error(f"BÅ‚Ä…d podczas treningu: {e}")
                logger.exception("Training failed")
    
    def _save_experiment(self, metrics: Dict, metadata: Dict):
        """Zapisuje eksperyment do bazy"""
        try:
            # OkreÅ›l typ problemu
            problem_type = ProblemType.REGRESSION
            if "accuracy" in metrics or "f1" in str(metrics).lower():
                problem_type = ProblemType.BINARY_CLASSIFICATION
            
            # UtwÃ³rz rekord
            record = RunRecord(
                dataset=self.state.dataset_name,
                target=self.state.target_column,
                run_id=metadata.get("run_id", f"run_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}"),
                problem_type=problem_type,
                engine=metadata.get("engine", "auto"),
                status=RunStatus.COMPLETED,
                metrics=metrics,
                parameters=metadata.get("model_params", {}),
                notes="Eksperyment z interfejsu TMIV",
                duration_seconds=metadata.get("run_time", 0)
            )
            
            success = self.experiment_tracker.log_run(record)
            if success:
                st.toast("ğŸ’¾ Eksperyment zapisany w historii", icon="âœ…")
            
        except Exception as e:
            st.warning(f"Nie udaÅ‚o siÄ™ zapisaÄ‡ eksperymentu: {e}")
            logger.exception("Failed to save experiment")
    
    def _results_phase(self):
        """Faza wynikÃ³w po treningu"""
        st.markdown("## ğŸ“Š Wyniki treningu")
        
        # Metryki
        self._render_metrics()
        
        # Feature importance
        self._render_feature_importance()
        
        # Rekomendacje
        self._render_recommendations()
        
        # Predykcje
        self._render_predictions()
        
        # Reset przyciski
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ Nowy eksperyment", use_container_width=True):
                self._reset_state()
        with col2:
            if st.button("ğŸ“¥ Pobierz wyniki", use_container_width=True):
                self._export_results()
    
    def _render_metrics(self):
        """Renderuje metryki modelu"""
        metrics = self.state.metrics
        
        if not metrics:
            return
            
        # GÅ‚Ã³wne metryki w kolumnach
        cols = st.columns(len(metrics))
        
        for i, (name, value) in enumerate(metrics.items()):
            if isinstance(value, (int, float)) and not pd.isna(value):
                with cols[i]:
                    st.metric(
                        name.upper(),
                        f"{value:.4f}" if isinstance(value, float) else str(value)
                    )
        
        # SzczegÃ³Å‚owe metryki
        with st.expander("ğŸ“Š Wszystkie metryki"):
            st.json(metrics)
    
    def _render_feature_importance(self):
        """Renderuje waÅ¼noÅ›Ä‡ cech"""
        fi_df = self.state.feature_importance
        
        if fi_df.empty:
            return
            
        st.subheader("ğŸ† NajwaÅ¼niejsze cechy")
        
        # Slider dla liczby cech
        max_features = min(20, len(fi_df))
        n_features = st.slider("Liczba cech do wyÅ›wietlenia", 5, max_features, 10)
        
        # Wykres
        top_features = fi_df.head(n_features)
        
        if px:
            fig = px.bar(
                top_features,
                x='importance',
                y='feature',
                orientation='h',
                title="WaÅ¼noÅ›Ä‡ cech"
            )
            fig.update_yaxes(categoryorder='total ascending')
            st.plotly_chart(fig, use_container_width=True)
        
        # Tabela
        st.dataframe(top_features, use_container_width=True)
    
    def _render_recommendations(self):
        """Renderuje rekomendacje AI/reguÅ‚y"""
        st.subheader("ğŸ’¡ Rekomendacje")
        
        # SprawdÅº czy jest klucz OpenAI
        openai_key = get_openai_key()
        
        if openai_key and not self.state.feature_importance.empty:
            # AI rekomendacje
            try:
                detector = SmartTargetDetector()
                analysis = detector.analyze_target(self.state.dataset, self.state.target_column)
                
                engine = MLRecommendationEngine()
                recommendations = engine.generate_recommendations(
                    analysis=analysis,
                    top_features=self.state.feature_importance.head(5)['feature'].tolist(),
                    dataset_size=len(self.state.dataset)
                )
                
                st.markdown(recommendations)
                
            except Exception as e:
                st.error(f"BÅ‚Ä…d generowania rekomendacji AI: {e}")
                self._render_rule_based_recommendations()
        else:
            # Podstawowe rekomendacje reguÅ‚y
            self._render_rule_based_recommendations()
    
    def _render_rule_based_recommendations(self):
        """Podstawowe rekomendacje oparte na reguÅ‚ach"""
        recommendations = []
        metrics = self.state.metrics
        
        # Rekomendacje dla regresji
        if 'r2' in metrics:
            r2 = metrics['r2']
            if r2 < 0.6:
                recommendations.append("â€¢ RÂ² < 0.6 - rozwaÅ¼ dodanie nowych cech lub transformacje danych")
            elif r2 > 0.95:
                recommendations.append("â€¢ RÂ² > 0.95 - sprawdÅº czy nie ma overfittingu")
        
        # Rekomendacje dla klasyfikacji
        if 'accuracy' in metrics:
            acc = metrics['accuracy']
            if acc < 0.8:
                recommendations.append("â€¢ Accuracy < 80% - sprawdÅº balans klas i jakoÅ›Ä‡ cech")
        
        # OgÃ³lne rekomendacje
        recommendations.extend([
            "â€¢ Przetestuj model na nowych danych",
            "â€¢ RozwaÅ¼ zbieranie dodatkowych danych",
            "â€¢ Monitoruj performance w czasie"
        ])
        
        for rec in recommendations:
            st.markdown(rec)

    # Dodaj pozostaÅ‚e brakujÄ…ce metody (jak w poprzednim artefakcie)

def main():
    try:
        app = TMIVApplication()
        
        # Renderuj nagÅ‚Ã³wek
        app._render_header()
        app._render_openai_status()
        
        # GÅ‚Ã³wny przepÅ‚yw
        if not app.state.training_completed:
            app._data_loading_phase()
        else:
            app._results_phase()
        
        # Sekcje dostÄ™pne zawsze
        app._render_history_section()
        app._render_sidebar_tools()
        
    except Exception as e:
        st.error(f"BÅ‚Ä…d aplikacji: {e}")